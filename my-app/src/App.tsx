import { useState, useEffect, useRef } from 'react';
import axios from 'axios'; // axios import ì¶”ê°€

const API_BASE_URL = 'http://localhost:8000'; // ë°±ì—”ë“œ API ê¸°ë³¸ ì£¼ì†Œ

// ì†ìƒ í´ë˜ìŠ¤ ì •ì˜
const DAMAGE_CLASSES = {
  0: 'ê¸°íƒ€',
  1: 'ê±°ë¶ë“± ê· ì—´',
  2: 'ë‚®',
  3: 'ë°¤',
  4: 'ë¶ˆëŸ‰ ë³´ìˆ˜',
  5: 'ì“°ë ˆê¸°',
  6: 'ì–‘í˜¸',
  7: 'ì –ì€ ë„ë¡œ',
  8: 'ì¢…ë°©í–¥ ê· ì—´',
  9: 'ì°¨ì„ ',
  10: 'ì°¨ì„  ì†ìƒ',
  11: 'í¬íŠ¸í™€',
  12: 'íš¡ë°©í–¥ ê· ì—´'
} as const;

// ì‹œê°ì  ê²½ê³ ë¥¼ í‘œì‹œí•´ì•¼ í•˜ëŠ” í´ë˜ìŠ¤ ID ëª©ë¡
const VISUAL_WARNING_CLASSES = [0, 1, 4, 5, 7, 8, 10, 11, 12] as const;

// API ì‘ë‹µ íƒ€ì… ì •ì˜
interface Prediction {
  class_id: number;
  name: string;
  confidence: number;
  type: string;
  x: number;
  y: number;
  width: number;
  height: number;
  width_cm: number;
  length_cm: number;
  area_m2: number;
  risk_level: 'A' | 'B' | 'C' | '-';
}

interface ApiResponse {
  predictions: Prediction[];
  day_or_night: string;
  overall_risk: 'A' | 'B' | 'C';
  original_image_url: string;
  result_image_url: string;
}

function App() {
  const [theme, setTheme] = useState('light');
  const [isCameraOn, setIsCameraOn] = useState(false);
  const [activeTab, setActiveTab] = useState('live');
  
  const cameraPreviewRef = useRef<HTMLDivElement>(null);
  const videoElementRef = useRef<HTMLVideoElement | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const speechSynthesisRef = useRef(window.speechSynthesis);

  // Detection and status states
  const [isProcessing, setIsProcessing] = useState(false);
  const [alertCount, setAlertCount] = useState(0);
  const [liveDetections, setLiveDetections] = useState<Array<any>>([]);
  const [historyDetections, _setHistoryDetections] = useState<Array<any>>([
    // Static history example data
    {
      id: 'hist1',
      name: DAMAGE_CLASSES[1],
      details: 'ì‹ ë¢°ë„: 95% â€¢ ì¢Œí‘œ: (240, 180)',
      shapeType: 'bbox',
      severity: 'high',
      time: '2ë¶„ ì „'
    },
    {
      id: 'hist2',
      name: DAMAGE_CLASSES[11],
      details: 'ì‹ ë¢°ë„: 87% â€¢ ì¢Œí‘œ: (320, 400)',
      shapeType: 'bbox',
      severity: 'medium',
      time: '5ë¶„ ì „'
    }
  ]);
  const [detectionOverlays, setDetectionOverlays] = useState<Array<any>>([]);

  // Status text states
  const [connectionStatusText, setConnectionStatusText] = useState('ëŒ€ê¸° ì¤‘');
  const [isConnectionOk, setIsConnectionOk] = useState(false);
  const [processingStatusText, setProcessingStatusText] = useState('ì¤€ë¹„ë¨');
  const simulationTimeoutRef = useRef<number | null>(null);
  const [previewMode, setPreviewMode] = useState<'placeholder' | 'video' | 'image'>('placeholder');
  const [imagePreviewUrl, setImagePreviewUrl] = useState<string | null>(null);
  const [activeView, setActiveView] = useState<'live' | 'upload'>('live');
  const [isImageAnalyzing, setIsImageAnalyzing] = useState(false);
  const [analysisResults, setAnalysisResults] = useState<Array<any>>([]);
  const [apiResponse, setApiResponse] = useState<any>(null);
  const uploadedImageRef = useRef<HTMLImageElement>(null);

  useEffect(() => {
    document.body.setAttribute('data-theme', theme);
  }, [theme]);

  const toggleTheme = () => {
    setTheme(prev => (prev === 'light' ? 'dark' : 'light'));
  };

  // Audio and Speech Synthesis Utilities
  const initAudioContext = () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
    }
  };

  const playAlertSound = () => {
    if (!audioContextRef.current) return;
    const context = audioContextRef.current;
    const oscillator = context.createOscillator();
    const gainNode = context.createGain();
    oscillator.connect(gainNode);
    gainNode.connect(context.destination);
    oscillator.frequency.setValueAtTime(800, context.currentTime);
    oscillator.frequency.setValueAtTime(1000, context.currentTime + 0.1);
    oscillator.frequency.setValueAtTime(800, context.currentTime + 0.2);
    gainNode.gain.setValueAtTime(0, context.currentTime);
    gainNode.gain.linearRampToValueAtTime(0.3, context.currentTime + 0.01);
    gainNode.gain.exponentialRampToValueAtTime(0.01, context.currentTime + 0.3);
    oscillator.start(context.currentTime);
    oscillator.stop(context.currentTime + 0.3);
  };

  const speakAlert = (text: string) => {
    if (speechSynthesisRef.current.speaking) {
      speechSynthesisRef.current.cancel();
    }
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = 1.2;
    utterance.pitch = 1;
    utterance.volume = 0.8;
    speechSynthesisRef.current.speak(utterance);
  };

  // Effect for detection simulation
  useEffect(() => {
    const simulateDetections = () => {
      if (!isProcessing || activeView !== 'live') return;

      const hazards = [
        { classId: 1, type: 'high', confidence: 95 },
        { classId: 11, type: 'medium', confidence: 87 },
        { classId: 10, type: 'medium', confidence: 92 },
      ];
      const hazard = hazards[Math.floor(Math.random() * hazards.length)];
      const previewWidth = cameraPreviewRef.current?.clientWidth || 512;
      const previewHeight = cameraPreviewRef.current?.clientHeight || 512;

      const x = Math.random() * (previewWidth * 0.7) + (previewWidth * 0.05);
      const y = Math.random() * (previewHeight * 0.7) + (previewHeight * 0.05);
      const width = Math.random() * (previewWidth * 0.2) + 50;
      const height = Math.random() * (previewHeight * 0.2) + 50;
      const overlayData = { type: 'bbox', x, y, width, height };
      
      addDetectionResult(
        DAMAGE_CLASSES[hazard.classId as keyof typeof DAMAGE_CLASSES],
        `ì‹ ë¢°ë„: ${hazard.confidence}%`,
        hazard.type,
        overlayData
      );

      simulationTimeoutRef.current = window.setTimeout(simulateDetections, Math.random() * 4000 + 2000);
    };

    if (isProcessing && activeView === 'live') {
      simulateDetections();
    } else {
      if (simulationTimeoutRef.current) clearTimeout(simulationTimeoutRef.current);
    }
    return () => { // Cleanup
      if (simulationTimeoutRef.current) clearTimeout(simulationTimeoutRef.current);
    };
  }, [isProcessing, activeView]);

  useEffect(() => {
    if (previewMode === 'video' && streamRef.current && videoElementRef.current && activeView === 'live') {
      videoElementRef.current.srcObject = streamRef.current;
    } else if (videoElementRef.current) {
      // Stop video playback when not in video mode to release resources
      // and prevent potential errors if srcObject is already null.
      videoElementRef.current.pause();
      videoElementRef.current.srcObject = null;
    }
  }, [previewMode, streamRef.current, activeView]); 

  const handleStartCamera = async () => {
    console.log('Start Camera Clicked');
    initAudioContext(); // Initialize audio context when camera starts
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 512 },
            height: { ideal: 512 },
            facingMode: 'environment'
          }
        });
        streamRef.current = stream;
        // The useEffect above will handle setting srcObject when previewMode changes to 'video'
        setPreviewMode('video');
        setIsCameraOn(true);
        setIsProcessing(true);
        setConnectionStatusText('ì—°ê²°ë¨');
        setIsConnectionOk(true);
        setProcessingStatusText('ì‹¤ì‹œê°„ ë¶„ì„ ì¤‘');
        setLiveDetections([]); 
        setDetectionOverlays([]);
      } catch (err) {
        console.error("Error accessing camera: ", err);
        alert('ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      }
    } else {
      alert('ì´ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ì¹´ë©”ë¼ ê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
    }
  };

  const handleStopCamera = () => {
    console.log('Stop Camera Clicked');
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }
    // The useEffect above will handle clearing srcObject when previewMode changes
    streamRef.current = null;
    setPreviewMode('placeholder');
    setIsCameraOn(false);
    setIsProcessing(false);
    setConnectionStatusText('ëŒ€ê¸° ì¤‘');
    setIsConnectionOk(false);
    setProcessingStatusText('ì¤€ë¹„ë¨');
  };

  const handleUploadImage = () => {
    console.log('Upload Image Clicked for Analysis View');
    const input = document.createElement('input');
    input.type = 'file';
    input.accept = 'image/*';
    input.onchange = (event) => {
      const target = event.target as HTMLInputElement;
      const file = target.files?.[0];
      if (file) { 
        initAudioContext();
        if (isCameraOn) handleStopCamera(); 

        setAnalysisResults([]); // Clear previous results
        setIsImageAnalyzing(true);
        setProcessingStatusText('ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...');

        const reader = new FileReader();
        reader.onload = async (e) => { 
          setImagePreviewUrl(e.target?.result as string);

          try {
            const fd = new FormData();
            fd.append('file', file);
            const { data: response } = await axios.post<ApiResponse>(
              `${API_BASE_URL}/predict`,
              fd,
              { headers: { 'Content-Type': 'multipart/form-data' } }
            );

            setApiResponse(response);  // API ì‘ë‹µ ì €ì¥
            // API ì‘ë‹µì˜ result_image_urlì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            if (response.result_image_url) {
              setImagePreviewUrl(response.result_image_url);
            }
            
            // predictions ë°°ì—´ì´ ìˆëŠ”ì§€ í™•ì¸
            const predictions = response?.predictions || [];
            
            // API ì‘ë‹µì„ í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            const formattedResults = predictions
              .map((prediction: Prediction, index: number) => ({
                id: `${prediction.class_id}-${prediction.x}-${prediction.y}-${Date.now()}-${index}`, // IDë¥¼ ë” ê³ ìœ í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
                name: prediction.name,
                type: prediction.type,
                x: prediction.x,
                y: prediction.y,
                width: prediction.width,
                height: prediction.height,
                severity: prediction.risk_level === 'A' ? 'high' : 
                         prediction.risk_level === 'B' ? 'medium' : 'low',
                confidence: prediction.confidence,
                details: `ì‹ ë¢°ë„: ${(prediction.confidence * 100).toFixed(1)}% â€¢ í¬ê¸°: ${prediction.width_cm.toFixed(1)}cm x ${prediction.length_cm.toFixed(1)}cm â€¢ ë©´ì : ${prediction.area_m2.toFixed(2)}ã¡`
              }));

            setAnalysisResults(formattedResults);
            setIsImageAnalyzing(false);
            setProcessingStatusText(`ë¶„ì„ ì™„ë£Œ: ${formattedResults.length}ê°œ í•­ëª© ë°œê²¬ (${response.day_or_night}, ì „ì²´ ìœ„í—˜ë„: ${response.overall_risk})`);

            if (response.overall_risk === 'A') {
              playAlertSound();
              speakAlert('ì´ë¯¸ì§€ì—ì„œ ê³ ìœ„í—˜ ìš”ì†Œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.');
            } else if (formattedResults.length > 0) {
              speakAlert(`ì´ë¯¸ì§€ ë¶„ì„ì´ ì™„ë£Œë˜ì–´ ${formattedResults.length}ê°œ í•­ëª©ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.`);
            } else {
              speakAlert('ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼, íŠ¹ì´ì‚¬í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
            }
          } catch (error) {
            console.error("Error uploading and analyzing image:", error);
            setIsImageAnalyzing(false);
            setProcessingStatusText('ì˜¤ë¥˜ ë°œìƒ: ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
            speakAlert('ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
          }
        };
        reader.readAsDataURL(file);
      }
    };
    input.click();
  };

  const handleTabClick = (tabName: string) => {
    console.log('Tab Clicked:', tabName);
    setActiveTab(tabName);
  };

  const handleViewChange = (view: 'live' | 'upload') => {
    setActiveView(view);
    if (view === 'upload') {
      if (isCameraOn) handleStopCamera(); // Stop camera if switching to upload view
      setLiveDetections([]); // Clear live detections
      setDetectionOverlays([]); // Clear live overlays
      setAlertCount(0);
    } else { // Switching to 'live' view
      setImagePreviewUrl(null); // Clear uploaded image preview
      setAnalysisResults([]); // Clear analysis results
      setProcessingStatusText('ì¤€ë¹„ë¨');
      // Reset any upload-specific states if necessary
    }
  };

  const addDetectionResult = (name: string, details: string, severity: string, overlayData?: any, createOverlay = true) => {
    setAlertCount(prev => prev + 1);
    if (activeView === 'live') { // Only update liveDetections if in live view
      const newDetection = { id: Date.now() + Math.random(), name, details, severity, time: 'ë°©ê¸ˆ', shapeType: overlayData?.type };
      setLiveDetections(prev => [newDetection, ...prev.slice(0, 9)]);
    }
    if (createOverlay && overlayData && isCameraOn && activeView === 'live') { // Overlay only for live view with camera on
      const overlayId = `overlay-${Date.now()}`;
      let newOverlay;
      if (overlayData.type === 'bbox') {
        newOverlay = { id: overlayId, name, severity, type: 'bbox', ...overlayData };
      }
      if (!newOverlay) return;

      setDetectionOverlays(prev => [...prev, newOverlay]);
      setTimeout(() => {
        setDetectionOverlays(prev => prev.filter(o => o.id !== overlayId));
      }, 3000); // Remove overlay after 3 seconds
    }

    if (severity === 'high') {
      playAlertSound();
      speakAlert(`ìœ„í—˜ ìš”ì†Œ ê°ì§€: ${name}`);
    }
  };

  // JSX for detection item
  const renderDetectionItem = (item: any) => (
    <div key={item.id} className={`detection-item severity-${item.severity} slide-in`}>
      <div className="detection-info">
        <div className="detection-name">{item.name}</div>
        <div className="detection-details">{item.details} {item.shapeType && `â€¢ ${item.shapeType === 'bbox' ? 'ë°”ìš´ë”© ë°•ìŠ¤' : ''}`}</div>
      </div>
      <div className="detection-meta">
        <div className="severity-badge">{item.severity === 'high' ? 'ë†’ìŒ' : item.severity === 'medium' ? 'ì¤‘ê°„' : 'ë‚®ìŒ'}</div>
        <div className="detection-time">{item.time}</div>
      </div>
    </div>
  );

  return (
    <>
      <header className="header">
        <nav className="nav">
          <div className="logo">ğŸš— RoadVision</div>
          <div className="header-controls">
            <div className="view-selector">
              <button
                className={`btn-view-select ${activeView === 'upload' ? 'active' : ''}`}
                onClick={() => handleViewChange('upload')}
              >
                ì´ë¯¸ì§€ ë¶„ì„
              </button>
              <button
                className={`btn-view-select ${activeView === 'live' ? 'active' : ''}`}
                onClick={() => handleViewChange('live')}
              >
                ì‹¤ì‹œê°„ ë„ë¡œ ë¶„ì„
              </button>
              
            </div>
            <button className="theme-toggle" title="í…Œë§ˆ ì „í™˜" onClick={toggleTheme}>
              {theme === 'light' ? 'â˜€ï¸' : 'ğŸŒ™'}
            </button>
            <div className="status-indicators">
              <div className={`status-indicator ${isConnectionOk ? 'status-connected' : ''}`}>
                <div className="status-dot"></div>
                <span>{connectionStatusText}</span>
              </div>
              <div className="status-indicator">
                <div className="status-dot"></div>
                <span>{processingStatusText}</span>
              </div>
            </div>
          </div>
        </nav>
      </header>

      <main className="dashboard">
        {activeView === 'live' && (
          <>
            {/* Camera Section for Live View */}
            <section className="camera-section">
              <div className="camera-header">
                <div className="camera-title">
                  ğŸ¥ ì‹¤ì‹œê°„ ë„ë¡œ ë¶„ì„ (ë°ëª¨)
                </div>
                <div className="camera-controls-mini">
                  {!isCameraOn ? (
                    <button className="btn-mini" onClick={handleStartCamera}>ì‹œì‘</button>
                  ) : (
                    <button 
                      className="btn-mini active"
                      onClick={handleStopCamera}
                    >
                      ì •ì§€
                    </button>
                  )}
                  {/* "ì—…ë¡œë“œ" ë²„íŠ¼ì€ ì‹¤ì‹œê°„ ë¶„ì„ ë·°ì—ì„œëŠ” ì œê±°í•˜ê±°ë‚˜ ë‹¤ë¥¸ ê¸°ëŠ¥ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥ */}
                </div>
              </div>
              
              <div className="camera-container">
                <div className="camera-preview" ref={cameraPreviewRef}>
                  {previewMode === 'placeholder' && (
                    <div className="camera-placeholder">
                      <p>ğŸ¥ ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•˜ì—¬<br/>ì‹¤ì‹œê°„ ë„ë¡œ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”</p>
                    </div>
                  )}
                  {previewMode === 'video' && (
                    <video
                      ref={videoElementRef}
                      autoPlay
                      playsInline
                      muted
                      style={{ width: '100%', height: '100%', objectFit: 'cover', borderRadius: '16px' }}
                    />
                  )}
                  {/* imagePreviewUrl is for upload view, so not rendered here in live view */}
                  <div className="detection-overlay"> 
                    <svg width="100%" height="100%" style={{ position: 'absolute', top: 0, left: 0 }}>
                      {detectionOverlays.map(overlay => {
                        let strokeColor = '#ff3366'; 
                        let labelBackgroundColor = '#ff3366';
                        let fillColor = 'rgba(255,51,102,0.1)';

                        if (overlay.severity === 'medium') {
                          strokeColor = '#ff8800';
                          labelBackgroundColor = '#ff8800';
                          fillColor = 'rgba(255,136,0,0.1)';
                        } else if (overlay.severity === 'low') {
                          strokeColor = '#ffdd00';
                          labelBackgroundColor = '#ffdd00';
                          fillColor = 'rgba(255,221,0,0.1)';
                        }

                        let labelX = overlay.x || 0;
                        let labelY = (overlay.y || 0) - 25;

                        return (
                          <g key={overlay.id}>
                            <rect x={overlay.x} y={overlay.y} width={overlay.width} height={overlay.height} style={{ fill: fillColor, stroke: strokeColor, strokeWidth: 2 }} />
                            <foreignObject x={labelX} y={labelY < 0 ? 0 : labelY} width="120" height="30"> 
                              <div className="detection-label" style={{ backgroundColor: labelBackgroundColor, color: overlay.severity === 'low' ? '#000' : '#fff', display: 'inline-block', padding: '3px 8px', borderRadius: '4px', fontSize: '0.75rem', fontWeight: 600, whiteSpace: 'nowrap' }}>
                                {overlay.name}
                              </div>
                            </foreignObject>
                          </g>
                        );
                      })}
                    </svg>
                  </div>
                </div>
              </div>
            </section>

            {/* Detection Panel for Live View */}
            <section className="detection-panel">
              <div className="panel-header">
                <div className="panel-title">
                  âš ï¸ íƒì§€ ê²°ê³¼
                </div>
                <div className="alert-count">{alertCount}ê°œ ê°ì§€ë¨</div>
              </div>
              <div className="panel-tabs">
                <div className={`tab ${activeTab === 'live' ? 'active' : ''}`} data-tab="live" onClick={() => handleTabClick('live')} > ì‹¤ì‹œê°„ </div>
                <div className={`tab ${activeTab === 'history' ? 'active' : ''}`} data-tab="history" onClick={() => handleTabClick('history')} > ê¸°ë¡ </div>
                <div className={`tab ${activeTab === 'stats' ? 'active' : ''}`} data-tab="stats" onClick={() => handleTabClick('stats')} > í†µê³„ </div>
              </div>
              <div className="panel-content">
                <div id="liveTab" className="tab-content" style={{ display: activeTab === 'live' ? 'block' : 'none' }}>
                  {liveDetections.length === 0 ? ( <div className="empty-state"> <div className="empty-state-icon">ğŸ”</div> <p>ìœ„í—˜ìš”ì†Œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ<br/>ê°ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤</p> </div> ) : ( liveDetections.map(renderDetectionItem) )}
                </div> 
                <div id="historyTab" className="tab-content" style={{ display: activeTab === 'history' ? 'block' : 'none' }}>
                  {historyDetections.length === 0 ? ( <div className="empty-state"> <div className="empty-state-icon">ğŸ“‚</div> <p>íƒì§€ ê¸°ë¡ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p> </div> ) : ( historyDetections.map(renderDetectionItem) )}
                </div>
                <div id="statsTab" className="tab-content" style={{ display: activeTab === 'stats' ? 'block' : 'none' }}>
                  <div style={{ padding: '1rem 0' }}> <div style={{ marginBottom: '1.5rem' }}> <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: '0.5rem' }}> <span>ì´ íƒì§€ ê±´ìˆ˜</span> <strong>23ê°œ</strong> </div> <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: '0.5rem' }}> <span>ê³ ìœ„í—˜</span> <span style={{ color: '#ff3366' }}>8ê°œ</span> </div> <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: '0.5rem' }}> <span>ì¤‘ìœ„í—˜</span> <span style={{ color: '#ff8800' }}>10ê°œ</span> </div> <div style={{ display: 'flex', justifyContent: 'space-between' }}> <span>ì €ìœ„í—˜</span> <span style={{ color: '#ffdd00' }}>5ê°œ</span> </div> </div> <div style={{ fontSize: '0.8rem', color: 'var(--text-secondary)' }}> ìµœê·¼ 1ì¼ê°„ì˜ í†µê³„ì…ë‹ˆë‹¤ </div> </div>
                </div>
              </div>
            </section>
          </>
        )}

        {activeView === 'upload' && (
          <section className="upload-section">
            <div className="upload-area">
            <h2 className="upload-title">ì´ë¯¸ì§€ ë¶„ì„ (API ì—°ë™)</h2>
              <button className="btn btn-upload" onClick={handleUploadImage}>
                ğŸ“ ì´ë¯¸ì§€ ì„ íƒ ë° ì—…ë¡œë“œ
              </button>
              <div className="image-analysis-area">
                {isImageAnalyzing && (
                  <div className="loading-spinner-container">
                    <div className="loading-spinner"></div>
                    <p>ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...</p>
                  </div>
                )}
                {imagePreviewUrl && !isImageAnalyzing && (
                  <div className="image-preview-container-upload">
                    <img ref={uploadedImageRef} src={imagePreviewUrl} alt="ì—…ë¡œë“œëœ ì´ë¯¸ì§€" />
                    
                  </div>
                )}
                {!imagePreviewUrl && !isImageAnalyzing && (
                  <div className="upload-placeholder"><p>ë¶„ì„í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.</p></div>
                )}
              </div>
            </div>
            <div className="analysis-results-panel">
              <h3>ë¶„ì„ ìƒíƒœ</h3>
              <div className="results-placeholder">
                <p>{processingStatusText}</p> 
                {!isImageAnalyzing && apiResponse && (
                  <div style={{ 
                    marginTop: '1rem', 
                    padding: '1rem', 
                    background: 'var(--bg-tertiary)', 
                    borderRadius: '8px',
                    fontSize: '0.9rem',
                    textAlign: 'left',
                    whiteSpace: 'pre-wrap',
                    overflowX: 'auto'
                  }}>
                    <div style={{ marginBottom: '0.5rem', fontWeight: 'bold' }}>ë¶„ì„ ì •ë³´:</div>
                    <div style={{ marginBottom: '0.5rem' }}>
                      <div>ì‹œê°„ëŒ€: {apiResponse.day_or_night}</div>
                      <div>ì „ì²´ ìœ„í—˜ë„: {apiResponse.overall_risk}</div>
                    </div>
                    <div style={{ marginBottom: '0.5rem', fontWeight: 'bold' }}>íƒì§€ ê²°ê³¼:</div>
                    <pre style={{ margin: 0 }}>
                      {JSON.stringify(apiResponse.predictions, null, 2)}
                    </pre>
                  </div>
                )}
              </div>
            </div>
          </section>
        )}
      </main>
    </>
  )
}


export default App